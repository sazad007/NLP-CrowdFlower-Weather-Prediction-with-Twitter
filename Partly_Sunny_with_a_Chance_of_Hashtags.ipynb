{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazad007/NLP-CrowdFlower-Weather-Prediction-with-Twitter/blob/main/Partly_Sunny_with_a_Chance_of_Hashtags.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tx1_2_6e-ELj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import KLDivergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stuRsRyHAroh",
        "outputId": "929de637-d6c7-434e-bf0a-28436c95892d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKWc2-kU_xWh",
        "outputId": "94380639-6c4d-4a77-8695-18dddf7e632b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oUTS3UQYBL8X"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load('/content/drive/MyDrive/word2vec-google-news.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-fn3glVDMuH",
        "outputId": "2a31415e-4cb7-42d9-f02d-bd657f84b102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words -= {'not', 'no', 'very'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bowwSrpd-cGK"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "X = data['tweet'].values\n",
        "y = data.iloc[:, 4:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AMKXTbqYAHCK"
      },
      "outputs": [],
      "source": [
        "def _tokenizer(sentence):\n",
        "  sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
        "  sentence = re.sub(r'http\\S+', ' ', sentence)\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "  sentence = sentence.lower().split()\n",
        "  words = [word for word in sentence if word in word2vec and word not in stop_words]\n",
        "  if not words:\n",
        "    return np.zeros(word2vec.vector_size)\n",
        "  else:\n",
        "    return np.mean([word2vec[word] for word in words], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1oALRu9UCSp4"
      },
      "outputs": [],
      "source": [
        "X_vec = np.array([_tokenizer(sentence) for sentence in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c86WvxfoHZ2t"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_s = y_train[:, 0:5]\n",
        "y_train_w = y_train[:, 5:9]\n",
        "y_train_k = y_train[:, 9:]\n",
        "\n",
        "y_test_s = y_test[:, 0:5]\n",
        "y_test_w = y_test[:, 5:9]\n",
        "y_test_k = y_test[:, 9:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2WqcvJND_12",
        "outputId": "d33f62c2-f5b2-4c3e-de25-b4f1ccf8188a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - kind_accuracy: 0.4649 - kind_loss: 0.2314 - loss: 2.1760 - sentiment_accuracy: 0.5828 - sentiment_loss: 1.1636 - when_accuracy: 0.7771 - when_loss: 0.7810 - val_kind_accuracy: 0.7298 - val_kind_loss: 0.1318 - val_loss: 1.8911 - val_sentiment_accuracy: 0.6405 - val_sentiment_loss: 1.0587 - val_when_accuracy: 0.7960 - val_when_loss: 0.7005\n",
            "Epoch 2/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7271 - kind_loss: 0.1332 - loss: 1.8754 - sentiment_accuracy: 0.6467 - sentiment_loss: 1.0455 - when_accuracy: 0.7970 - when_loss: 0.6966 - val_kind_accuracy: 0.7666 - val_kind_loss: 0.1189 - val_loss: 1.8450 - val_sentiment_accuracy: 0.6539 - val_sentiment_loss: 1.0309 - val_when_accuracy: 0.7996 - val_when_loss: 0.6951\n",
            "Epoch 3/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - kind_accuracy: 0.7516 - kind_loss: 0.1241 - loss: 1.8495 - sentiment_accuracy: 0.6528 - sentiment_loss: 1.0320 - when_accuracy: 0.7979 - when_loss: 0.6935 - val_kind_accuracy: 0.7862 - val_kind_loss: 0.1137 - val_loss: 1.8265 - val_sentiment_accuracy: 0.6610 - val_sentiment_loss: 1.0225 - val_when_accuracy: 0.8001 - val_when_loss: 0.6902\n",
            "Epoch 4/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - kind_accuracy: 0.7697 - kind_loss: 0.1185 - loss: 1.8251 - sentiment_accuracy: 0.6590 - sentiment_loss: 1.0250 - when_accuracy: 0.8027 - when_loss: 0.6815 - val_kind_accuracy: 0.7899 - val_kind_loss: 0.1114 - val_loss: 1.8134 - val_sentiment_accuracy: 0.6651 - val_sentiment_loss: 1.0161 - val_when_accuracy: 0.8045 - val_when_loss: 0.6858\n",
            "Epoch 5/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7763 - kind_loss: 0.1162 - loss: 1.8078 - sentiment_accuracy: 0.6622 - sentiment_loss: 1.0153 - when_accuracy: 0.8073 - when_loss: 0.6763 - val_kind_accuracy: 0.7905 - val_kind_loss: 0.1095 - val_loss: 1.8016 - val_sentiment_accuracy: 0.6700 - val_sentiment_loss: 1.0112 - val_when_accuracy: 0.8052 - val_when_loss: 0.6808\n",
            "Epoch 6/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7791 - kind_loss: 0.1140 - loss: 1.7930 - sentiment_accuracy: 0.6704 - sentiment_loss: 1.0048 - when_accuracy: 0.8028 - when_loss: 0.6743 - val_kind_accuracy: 0.7970 - val_kind_loss: 0.1082 - val_loss: 1.7959 - val_sentiment_accuracy: 0.6740 - val_sentiment_loss: 1.0081 - val_when_accuracy: 0.8073 - val_when_loss: 0.6796\n",
            "Epoch 7/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - kind_accuracy: 0.7779 - kind_loss: 0.1132 - loss: 1.7690 - sentiment_accuracy: 0.6760 - sentiment_loss: 0.9940 - when_accuracy: 0.8119 - when_loss: 0.6617 - val_kind_accuracy: 0.8012 - val_kind_loss: 0.1071 - val_loss: 1.7917 - val_sentiment_accuracy: 0.6740 - val_sentiment_loss: 1.0056 - val_when_accuracy: 0.8063 - val_when_loss: 0.6790\n",
            "Epoch 8/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - kind_accuracy: 0.7799 - kind_loss: 0.1122 - loss: 1.7660 - sentiment_accuracy: 0.6804 - sentiment_loss: 0.9933 - when_accuracy: 0.8101 - when_loss: 0.6606 - val_kind_accuracy: 0.7978 - val_kind_loss: 0.1075 - val_loss: 1.7867 - val_sentiment_accuracy: 0.6775 - val_sentiment_loss: 1.0026 - val_when_accuracy: 0.8092 - val_when_loss: 0.6765\n",
            "Epoch 9/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - kind_accuracy: 0.7849 - kind_loss: 0.1113 - loss: 1.7581 - sentiment_accuracy: 0.6813 - sentiment_loss: 0.9894 - when_accuracy: 0.8138 - when_loss: 0.6574 - val_kind_accuracy: 0.8002 - val_kind_loss: 0.1067 - val_loss: 1.7877 - val_sentiment_accuracy: 0.6727 - val_sentiment_loss: 1.0003 - val_when_accuracy: 0.8065 - val_when_loss: 0.6805\n",
            "Epoch 10/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7839 - kind_loss: 0.1109 - loss: 1.7431 - sentiment_accuracy: 0.6858 - sentiment_loss: 0.9806 - when_accuracy: 0.8140 - when_loss: 0.6515 - val_kind_accuracy: 0.8006 - val_kind_loss: 0.1058 - val_loss: 1.7792 - val_sentiment_accuracy: 0.6770 - val_sentiment_loss: 0.9980 - val_when_accuracy: 0.8088 - val_when_loss: 0.6754\n",
            "Epoch 11/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - kind_accuracy: 0.7868 - kind_loss: 0.1106 - loss: 1.7346 - sentiment_accuracy: 0.6876 - sentiment_loss: 0.9776 - when_accuracy: 0.8179 - when_loss: 0.6464 - val_kind_accuracy: 0.8012 - val_kind_loss: 0.1056 - val_loss: 1.7805 - val_sentiment_accuracy: 0.6798 - val_sentiment_loss: 0.9980 - val_when_accuracy: 0.8073 - val_when_loss: 0.6768\n",
            "Epoch 12/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - kind_accuracy: 0.7825 - kind_loss: 0.1107 - loss: 1.7287 - sentiment_accuracy: 0.6932 - sentiment_loss: 0.9735 - when_accuracy: 0.8156 - when_loss: 0.6445 - val_kind_accuracy: 0.7980 - val_kind_loss: 0.1061 - val_loss: 1.7857 - val_sentiment_accuracy: 0.6752 - val_sentiment_loss: 1.0008 - val_when_accuracy: 0.8055 - val_when_loss: 0.6786\n",
            "Epoch 13/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - kind_accuracy: 0.7904 - kind_loss: 0.1097 - loss: 1.7233 - sentiment_accuracy: 0.6935 - sentiment_loss: 0.9711 - when_accuracy: 0.8205 - when_loss: 0.6425 - val_kind_accuracy: 0.7996 - val_kind_loss: 0.1054 - val_loss: 1.7797 - val_sentiment_accuracy: 0.6790 - val_sentiment_loss: 0.9976 - val_when_accuracy: 0.8079 - val_when_loss: 0.6766\n",
            "Epoch 14/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7852 - kind_loss: 0.1093 - loss: 1.7075 - sentiment_accuracy: 0.6965 - sentiment_loss: 0.9647 - when_accuracy: 0.8214 - when_loss: 0.6336 - val_kind_accuracy: 0.8019 - val_kind_loss: 0.1050 - val_loss: 1.7765 - val_sentiment_accuracy: 0.6809 - val_sentiment_loss: 0.9948 - val_when_accuracy: 0.8086 - val_when_loss: 0.6767\n",
            "Epoch 15/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7873 - kind_loss: 0.1097 - loss: 1.6982 - sentiment_accuracy: 0.7020 - sentiment_loss: 0.9563 - when_accuracy: 0.8219 - when_loss: 0.6322 - val_kind_accuracy: 0.8029 - val_kind_loss: 0.1047 - val_loss: 1.7732 - val_sentiment_accuracy: 0.6800 - val_sentiment_loss: 0.9939 - val_when_accuracy: 0.8106 - val_when_loss: 0.6745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a1d7a7b7050>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_layer = Input(shape=(word2vec.vector_size,))\n",
        "x = Dense(units=600, activation='relu')(input_layer)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(units=300, activation='relu')(x)\n",
        "\n",
        "sentiment_ = Dense(units=5, activation='softmax', name='sentiment')(x)\n",
        "when_ =  Dense(units=4, activation='softmax', name='when')(x)\n",
        "kind_ = Dense(units=15, activation='sigmoid', name='kind')(x)\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs = input_layer,\n",
        "    outputs= [sentiment_, when_, kind_]\n",
        ")\n",
        "\n",
        "losses = {\n",
        "    'sentiment': 'categorical_crossentropy',\n",
        "    'when': 'categorical_crossentropy',\n",
        "    'kind': 'binary_crossentropy'\n",
        "}\n",
        "\n",
        "metrics = {\n",
        "    'sentiment': 'accuracy',\n",
        "    'when': 'accuracy',\n",
        "    'kind': 'accuracy'\n",
        "}\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses, metrics=metrics)\n",
        "model.fit(x=X_train, y=[y_train_s, y_train_w, y_train_k], epochs=15, validation_data=(X_test, [y_test_s, y_test_w, y_test_k]), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shz02HroSSXk",
        "outputId": "f22d42fe-827b-470b-d202-0949a6ea8310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - kind_accuracy: 0.8046 - kind_loss: 0.1058 - loss: 1.7619 - sentiment_accuracy: 0.6851 - sentiment_loss: 0.9856 - when_accuracy: 0.8099 - when_loss: 0.6705\n",
            "Test loss and accuracy: [1.7731682062149048, 0.994252622127533, 0.6743028163909912, 0.10482947528362274, 0.8028864860534668, 0.6799871921539307, 0.8106478452682495]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test, [y_test_s, y_test_w, y_test_k])\n",
        "print(\"Test loss and accuracy:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6nhz_vM2TIz",
        "outputId": "e1a500c1-39ac-4e0b-833a-6bff7b3dd5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "          0         1         2         3         4\n",
            "0  0.059585  0.708592  0.071413  0.016249  0.144162\n",
            "          0         1         2         3\n",
            "0  0.468103  0.034783  0.057896  0.439217\n",
            "         0         1        2         3         4         5         6   \\\n",
            "0  0.137086  0.107765  0.00181  0.019486  0.001018  0.000589  0.119888   \n",
            "\n",
            "         7         8         9         10        11        12       13  \\\n",
            "0  0.010288  0.068035  0.074769  0.001715  0.573925  0.100686  0.00024   \n",
            "\n",
            "         14  \n",
            "0  0.022258  \n"
          ]
        }
      ],
      "source": [
        "sentence = 'it was a bad stormy day yesterday'\n",
        "X_v = np.array([_tokenizer(sentence)])\n",
        "\n",
        "y_pred = model.predict(X_v)\n",
        "\n",
        "s, w, k = y_pred\n",
        "\n",
        "s = pd.DataFrame(s)\n",
        "print(s)\n",
        "\n",
        "w = pd.DataFrame(w)\n",
        "print(w)\n",
        "\n",
        "k = pd.DataFrame(k)\n",
        "print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S2o1wCyw59I9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe479c02-2c8f-4876-aa8f-1dce178da7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1318/1318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n"
          ]
        }
      ],
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "X_t = test_data['tweet'].values\n",
        "X_t = np.array([_tokenizer(sentence) for sentence in X_t])\n",
        "\n",
        "y_pred = model.predict(X_t)\n",
        "s, w, k = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U0kNtTa87F4_"
      },
      "outputs": [],
      "source": [
        "np.savetxt('output.csv', np.column_stack((test_data['id'], s, w, k)), header='id,s1,s2,s3,s4,s5,w1,w2,w3,w4,k1,k2,k3,k4,k5,k6,k7,k8,k9,k10,k11,k12,k13,k14,k15', comments='', delimiter=',', fmt=['%d', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOCN6zHzoUAjSJftoqC2BF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}