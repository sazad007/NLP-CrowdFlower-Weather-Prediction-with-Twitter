{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazad007/NLP-Partly_Sunny_with_a_Chance_of_Hashtags/blob/main/Partly_Sunny_with_a_Chance_of_Hashtags.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "tx1_2_6e-ELj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import KLDivergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stuRsRyHAroh",
        "outputId": "4a11eaf5-b96b-47a5-bd25-9c2f30628ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKWc2-kU_xWh",
        "outputId": "69a54f64-1fb1-40ea-9561-2ddf95f2041a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "oUTS3UQYBL8X"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load('/content/drive/MyDrive/word2vec-google-news.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-fn3glVDMuH",
        "outputId": "dbb22bbc-881d-412e-e9fd-72a0d21b9e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words -= {'not', 'no', 'very'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "bowwSrpd-cGK"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "X = data['tweet'].values\n",
        "y = data.iloc[:, 4:].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "AMKXTbqYAHCK"
      },
      "outputs": [],
      "source": [
        "def _tokenizer(sentence):\n",
        "  sentence = re.sub('[^a-zA-Z]', ' ', sentence).lower().split()\n",
        "  words = [word for word in sentence if word in word2vec and word not in stop_words]\n",
        "  if not words:\n",
        "    return np.zeros(word2vec.vector_size)\n",
        "  else:\n",
        "    return np.mean([word2vec[word] for word in words], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1oALRu9UCSp4"
      },
      "outputs": [],
      "source": [
        "X_vec = np.array([_tokenizer(sentence) for sentence in X])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "c86WvxfoHZ2t"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_s = y_train[:, 0:5]\n",
        "y_train_w = y_train[:, 5:9]\n",
        "y_train_k = y_train[:, 9:]\n",
        "\n",
        "y_test_s = y_test[:, 0:5]\n",
        "y_test_w = y_test[:, 5:9]\n",
        "y_test_k = y_test[:, 9:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2WqcvJND_12",
        "outputId": "7930801e-2ac5-4589-a689-ac938313ac34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - kind_accuracy: 0.4719 - kind_loss: 0.2248 - loss: 2.1663 - sentiment_accuracy: 0.5802 - sentiment_loss: 1.1644 - when_accuracy: 0.7776 - when_loss: 0.7771 - val_kind_accuracy: 0.7270 - val_kind_loss: 0.1341 - val_loss: 1.8784 - val_sentiment_accuracy: 0.6504 - val_sentiment_loss: 1.0426 - val_when_accuracy: 0.7966 - val_when_loss: 0.7016\n",
            "Epoch 2/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - kind_accuracy: 0.7290 - kind_loss: 0.1339 - loss: 1.8865 - sentiment_accuracy: 0.6453 - sentiment_loss: 1.0519 - when_accuracy: 0.7990 - when_loss: 0.7007 - val_kind_accuracy: 0.7725 - val_kind_loss: 0.1197 - val_loss: 1.8431 - val_sentiment_accuracy: 0.6528 - val_sentiment_loss: 1.0278 - val_when_accuracy: 0.7974 - val_when_loss: 0.6955\n",
            "Epoch 3/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - kind_accuracy: 0.7551 - kind_loss: 0.1239 - loss: 1.8445 - sentiment_accuracy: 0.6572 - sentiment_loss: 1.0303 - when_accuracy: 0.8013 - when_loss: 0.6903 - val_kind_accuracy: 0.7835 - val_kind_loss: 0.1150 - val_loss: 1.8336 - val_sentiment_accuracy: 0.6570 - val_sentiment_loss: 1.0253 - val_when_accuracy: 0.8038 - val_when_loss: 0.6934\n",
            "Epoch 4/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - kind_accuracy: 0.7649 - kind_loss: 0.1200 - loss: 1.8284 - sentiment_accuracy: 0.6620 - sentiment_loss: 1.0237 - when_accuracy: 0.7992 - when_loss: 0.6848 - val_kind_accuracy: 0.7845 - val_kind_loss: 0.1117 - val_loss: 1.8109 - val_sentiment_accuracy: 0.6665 - val_sentiment_loss: 1.0161 - val_when_accuracy: 0.8052 - val_when_loss: 0.6830\n",
            "Epoch 5/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7759 - kind_loss: 0.1164 - loss: 1.8101 - sentiment_accuracy: 0.6639 - sentiment_loss: 1.0158 - when_accuracy: 0.8027 - when_loss: 0.6779 - val_kind_accuracy: 0.7898 - val_kind_loss: 0.1097 - val_loss: 1.8019 - val_sentiment_accuracy: 0.6715 - val_sentiment_loss: 1.0122 - val_when_accuracy: 0.8058 - val_when_loss: 0.6800\n",
            "Epoch 6/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - kind_accuracy: 0.7743 - kind_loss: 0.1152 - loss: 1.7942 - sentiment_accuracy: 0.6661 - sentiment_loss: 1.0097 - when_accuracy: 0.8064 - when_loss: 0.6693 - val_kind_accuracy: 0.7924 - val_kind_loss: 0.1083 - val_loss: 1.7962 - val_sentiment_accuracy: 0.6708 - val_sentiment_loss: 1.0060 - val_when_accuracy: 0.8062 - val_when_loss: 0.6818\n",
            "Epoch 7/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - kind_accuracy: 0.7785 - kind_loss: 0.1133 - loss: 1.7745 - sentiment_accuracy: 0.6777 - sentiment_loss: 0.9983 - when_accuracy: 0.8097 - when_loss: 0.6630 - val_kind_accuracy: 0.7964 - val_kind_loss: 0.1077 - val_loss: 1.7905 - val_sentiment_accuracy: 0.6714 - val_sentiment_loss: 1.0045 - val_when_accuracy: 0.8074 - val_when_loss: 0.6783\n",
            "Epoch 8/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7820 - kind_loss: 0.1123 - loss: 1.7692 - sentiment_accuracy: 0.6780 - sentiment_loss: 0.9961 - when_accuracy: 0.8075 - when_loss: 0.6608 - val_kind_accuracy: 0.7990 - val_kind_loss: 0.1069 - val_loss: 1.7900 - val_sentiment_accuracy: 0.6746 - val_sentiment_loss: 1.0037 - val_when_accuracy: 0.8050 - val_when_loss: 0.6793\n",
            "Epoch 9/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - kind_accuracy: 0.7828 - kind_loss: 0.1113 - loss: 1.7533 - sentiment_accuracy: 0.6801 - sentiment_loss: 0.9852 - when_accuracy: 0.8137 - when_loss: 0.6568 - val_kind_accuracy: 0.7983 - val_kind_loss: 0.1064 - val_loss: 1.7933 - val_sentiment_accuracy: 0.6746 - val_sentiment_loss: 1.0050 - val_when_accuracy: 0.8068 - val_when_loss: 0.6819\n",
            "Epoch 10/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - kind_accuracy: 0.7832 - kind_loss: 0.1108 - loss: 1.7397 - sentiment_accuracy: 0.6893 - sentiment_loss: 0.9795 - when_accuracy: 0.8128 - when_loss: 0.6495 - val_kind_accuracy: 0.7996 - val_kind_loss: 0.1064 - val_loss: 1.7832 - val_sentiment_accuracy: 0.6790 - val_sentiment_loss: 0.9994 - val_when_accuracy: 0.8065 - val_when_loss: 0.6773\n",
            "Epoch 11/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - kind_accuracy: 0.7840 - kind_loss: 0.1104 - loss: 1.7348 - sentiment_accuracy: 0.6908 - sentiment_loss: 0.9744 - when_accuracy: 0.8136 - when_loss: 0.6499 - val_kind_accuracy: 0.7989 - val_kind_loss: 0.1058 - val_loss: 1.7853 - val_sentiment_accuracy: 0.6790 - val_sentiment_loss: 0.9958 - val_when_accuracy: 0.8051 - val_when_loss: 0.6835\n",
            "Epoch 12/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - kind_accuracy: 0.7875 - kind_loss: 0.1100 - loss: 1.7220 - sentiment_accuracy: 0.6918 - sentiment_loss: 0.9689 - when_accuracy: 0.8170 - when_loss: 0.6430 - val_kind_accuracy: 0.8004 - val_kind_loss: 0.1056 - val_loss: 1.7835 - val_sentiment_accuracy: 0.6777 - val_sentiment_loss: 1.0004 - val_when_accuracy: 0.8103 - val_when_loss: 0.6774\n",
            "Epoch 13/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - kind_accuracy: 0.7910 - kind_loss: 0.1091 - loss: 1.7113 - sentiment_accuracy: 0.6983 - sentiment_loss: 0.9656 - when_accuracy: 0.8220 - when_loss: 0.6365 - val_kind_accuracy: 0.8026 - val_kind_loss: 0.1057 - val_loss: 1.7778 - val_sentiment_accuracy: 0.6801 - val_sentiment_loss: 0.9946 - val_when_accuracy: 0.8071 - val_when_loss: 0.6774\n",
            "Epoch 14/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - kind_accuracy: 0.7891 - kind_loss: 0.1099 - loss: 1.7063 - sentiment_accuracy: 0.6990 - sentiment_loss: 0.9627 - when_accuracy: 0.8205 - when_loss: 0.6337 - val_kind_accuracy: 0.8001 - val_kind_loss: 0.1055 - val_loss: 1.7805 - val_sentiment_accuracy: 0.6795 - val_sentiment_loss: 0.9955 - val_when_accuracy: 0.8051 - val_when_loss: 0.6793\n",
            "Epoch 15/15\n",
            "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - kind_accuracy: 0.7881 - kind_loss: 0.1088 - loss: 1.6990 - sentiment_accuracy: 0.6985 - sentiment_loss: 0.9637 - when_accuracy: 0.8234 - when_loss: 0.6265 - val_kind_accuracy: 0.8044 - val_kind_loss: 0.1049 - val_loss: 1.7778 - val_sentiment_accuracy: 0.6820 - val_sentiment_loss: 0.9936 - val_when_accuracy: 0.8067 - val_when_loss: 0.6791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae6d83dab10>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "input_layer = Input(shape=(word2vec.vector_size,))\n",
        "x = Dense(units=600, activation='relu')(input_layer)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(units=300, activation='relu')(x)\n",
        "\n",
        "sentiment_ = Dense(units=5, activation='softmax', name='sentiment')(x)\n",
        "when_ =  Dense(units=4, activation='softmax', name='when')(x)\n",
        "kind_ = Dense(units=15, activation='sigmoid', name='kind')(x)\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs = input_layer,\n",
        "    outputs= [sentiment_, when_, kind_]\n",
        ")\n",
        "\n",
        "losses = {\n",
        "    'sentiment': 'categorical_crossentropy',\n",
        "    'when': 'categorical_crossentropy',\n",
        "    'kind': 'binary_crossentropy'\n",
        "}\n",
        "\n",
        "metrics = {\n",
        "    'sentiment': 'accuracy',\n",
        "    'when': 'accuracy',\n",
        "    'kind': 'accuracy'\n",
        "}\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses, metrics=metrics)\n",
        "model.fit(x=X_train, y=[y_train_s, y_train_w, y_train_k], epochs=15, validation_data=(X_test, [y_test_s, y_test_w, y_test_k]), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shz02HroSSXk",
        "outputId": "ef4fd0ff-c389-446a-8b22-966184bc633f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - kind_accuracy: 0.8004 - kind_loss: 0.1061 - loss: 1.7657 - sentiment_accuracy: 0.6817 - sentiment_loss: 0.9851 - when_accuracy: 0.8062 - when_loss: 0.6745\n",
            "Test loss and accuracy: [1.7778160572052002, 0.994020402431488, 0.6788996458053589, 0.10500539094209671, 0.8043617606163025, 0.6819756031036377, 0.806735098361969]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test, [y_test_s, y_test_w, y_test_k])\n",
        "print(\"Test loss and accuracy:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6nhz_vM2TIz",
        "outputId": "f1359fab-af35-46fc-c71b-819686134ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
            "          0         1         2         3         4\n",
            "0  0.039956  0.785734  0.065022  0.080945  0.028343\n",
            "          0         1         2         3\n",
            "0  0.923357  0.006972  0.027897  0.041774\n",
            "        0         1         2         3         4         5        6   \\\n",
            "0  0.02167  0.001254  0.001406  0.002118  0.000848  0.000177  0.93524   \n",
            "\n",
            "         7       8         9         10        11       12        13        14  \n",
            "0  0.000265  0.1118  0.007221  0.000143  0.002793  0.00513  0.000384  0.000643  \n"
          ]
        }
      ],
      "source": [
        "sentence = 'Very bad weather today'\n",
        "X_v = np.array([_tokenizer(sentence)])\n",
        "\n",
        "y_pred = model.predict(X_v)\n",
        "\n",
        "s, w, k = y_pred\n",
        "\n",
        "s = pd.DataFrame(s)\n",
        "print(s)\n",
        "\n",
        "w = pd.DataFrame(w)\n",
        "print(w)\n",
        "\n",
        "k = pd.DataFrame(k)\n",
        "print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "S2o1wCyw59I9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d3252d-f0ef-4761-d148-1eb0b3028553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1318/1318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "X_t = test_data['tweet'].values\n",
        "X_t = np.array([_tokenizer(sentence) for sentence in X_t])\n",
        "\n",
        "y_pred = model.predict(X_t)\n",
        "s, w, k = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "U0kNtTa87F4_"
      },
      "outputs": [],
      "source": [
        "np.savetxt('output.csv', np.column_stack((test_data['id'], s, w, k)), header='id,s1,s2,s3,s4,s5,w1,w2,w3,w4,k1,k2,k3,k4,k5,k6,k7,k8,k9,k10,k11,k12,k13,k14,k15', comments='', delimiter=',', fmt=['%d', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f', '%.3f'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9yw9IaZSMe1fS3lRBADqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}